# 第5回B4輪講課題

## 課題の概要

本課題では, 変分ベイズによるGMMベースのソフトクラスタリング+αを行う.

## 課題

1. データの準備
   - data1.csv, data2.csv, data3.csvの散布図をプロットして概形を確認
     - 前回と同じデータです.

2. 実装済みのGMMVB（変分ベイズによる混合ガウス分布のパラメータ推定）をデータに適用
   - https://academ-aid.com/ml/vb のGMMVBクラスを使用して, パラメータ推定をしてください.
     - クラスター数は主観で決めてもらっても構いません.
     - 必要に応じて各メソッドを改変してもらっても構いません.
   - 散布図上に混合分布の等高線を図示したものを画像ファイルに保存してください. 
     - 各データ点を所属確率（負担率）に基づいて, グラデーションで色付けするとより分かりやすいと思います.

3.  ベイズ信用区間の算出
   - 上記の実装を改変して, 各μₖの95% Highest Density Interval (HDI) を算出してください.
     - 以下に挙げる大きく分けて2つの方法のどちらかを推奨します（簡単な順）.
       - 方法1: 正規近似による解析的区間（mₖ±z·σで近似）
         - 1次元なら分散 σ²＝Wₖ, 多次元なら対角要素 σⱼ²＝diag(Wₖ)[j] (Wₖ: 分散共分散行列).
         - z=1.96（正規分布95%点）とする.
         -  HDIⱼ = [ mₖⱼ − 1.96·√(σⱼ²), mₖⱼ + 1.96·√(σⱼ²) ] とする.
       - 方法2: サンプリング+最短区間切り出し
         - 事後分布 q(μₖ) = 𝒩(mₖ,Wₖ) から n ≈ 10,000～100,000 のサンプルXを得る.
         - ある次元について, サンプルを昇順ソートする (x₍₁₎ ≤ x₍₂₎ ≤ … ≤ x₍ₙ₎とする). 
         - l = 0.95 × n, Lᵢ = x₍ᵢ₊ₗ₎ − x₍ᵢ₎ として, i* = argminᵢ Lᵢ を求める.
         - HDI = [ x₍ᵢ*₎,  x₍ᵢ*₊ₗ₎ ] とする.
         - 上記の流れ（昇順ソート以下）を全ての次元で行う.
     - 2.で作成した図の上に可視化したものを画像ファイルに保存してください.
       - 等高線と被るので, 色分けするor等高線を目立たなくするor等高線を消すなどすると良いでしょう. 





## 発表（次週）
   - 取り組んだ内容を周りにわかるように説明
   - コードの解説
     - 工夫したところ，苦労したところの解決策はぜひ共有しましょう
   - 結果の考察，応用先の調査など
   - 発表資料はTeamsにアップロードしておくこと

## 余裕がある人は

- 出来る限り可読性，高速化を意識しましょう
  - 冗長な記述はしていませんか
  - for文は行列演算に置き換えることはできませんか
  - pythonで実行時間を測定する方法は[こちら](http://st-hakky.hatenablog.com/entry/2018/01/26/214255)


## 注意

- 武田研究室の場合はセットアップで作成した`virtualenv`環境を利用すること
  - アクティベート例：`source ~/workspace3/myvenv/bin/activate`
  - アクティベート後`pip install ...`でライブラリのインストールを行う
- 自分の作業ブランチで課題を行うこと
- プルリクエストを送る前に[REVIEW.md](https://github.com/TakedaLab/B4Lecture/blob/master/REVIEW.md)を参照し直せるところは直すこと
- プルリクエストをおくる際には**実行結果の画像も載せること**
- 作業前にリポジトリを最新版に更新すること

```
$ git checkout master
$ git fetch upstream
$ git merge upstresam/master
```
